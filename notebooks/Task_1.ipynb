{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10bb684",
   "metadata": {},
   "source": [
    "Задание 1 Реализация нейронной сети с двумя сверточными слоями и одним полносвязным с кусочко-линейной функцией активации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb15635",
   "metadata": {},
   "source": [
    "1) Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8c30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa25f5e5",
   "metadata": {},
   "source": [
    "2) Настройка вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2bb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2600a9e0410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2835f71",
   "metadata": {},
   "source": [
    "3) Загрузка подготовленного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa41a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: torch.Size([415752, 1, 28, 28]) torch.Size([415752])\n",
      "val:   torch.Size([46194, 1, 28, 28]) torch.Size([46194])\n",
      "test:  torch.Size([13649, 1, 28, 28]) torch.Size([13649])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"..\\data\\prepared\\notmnist_28.npz\"\n",
    "assert os.path.exists(DATA_PATH), f\"File not found: {DATA_PATH}\"\n",
    "\n",
    "d = np.load(DATA_PATH)\n",
    "\n",
    "X_train = torch.tensor(d[\"X_train\"], dtype=torch.float32)\n",
    "y_train = torch.tensor(d[\"y_train\"], dtype=torch.long)\n",
    "\n",
    "X_val = torch.tensor(d[\"X_val\"], dtype=torch.float32)\n",
    "y_val = torch.tensor(d[\"y_val\"], dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(d[\"X_test\"], dtype=torch.float32)\n",
    "y_test = torch.tensor(d[\"y_test\"], dtype=torch.long)\n",
    "\n",
    "print(\"train:\", X_train.shape, y_train.shape)\n",
    "print(\"val:  \", X_val.shape, y_val.shape)\n",
    "print(\"test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f4101",
   "metadata": {},
   "source": [
    "4) Фомирование DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce04c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val),     batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(TensorDataset(X_test, y_test),   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43808b7b",
   "metadata": {},
   "source": [
    "5) Определение архитектуры нейронной сети (2 сверточных слоя + 1 полносвязный слой, активация кусочко-линейная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc6aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            self.act = nn.ReLU()\n",
    "        elif activation == \"leakyrelu\":\n",
    "            self.act = nn.LeakyReLU(0.1)\n",
    "        else:\n",
    "            raise ValueError(\"activation must be 'relu' or 'leakyrelu'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9865e80",
   "metadata": {},
   "source": [
    "6) Проверка корректности размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f072fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleConvNet(activation=\"relu\").to(device)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb = xb.to(device)\n",
    "\n",
    "out = model(xb)\n",
    "print(\"out shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5eae8f",
   "metadata": {},
   "source": [
    "7) Оптимизатор и гиперпараметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a585d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "EPOCHS = 30\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be6e9d",
   "metadata": {},
   "source": [
    "8) Функции обучения и оценки качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f95285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y).float().mean().item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        bs = X.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc += accuracy(logits, y) * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / n, total_acc / n\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = X.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc += accuracy(logits, y) * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / n, total_acc / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9ae10",
   "metadata": {},
   "source": [
    "9) Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3bfe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train loss=0.4374, acc=0.8779 | val loss=0.3809, acc=0.8942\n",
      "Epoch 02: train loss=0.3568, acc=0.9002 | val loss=0.3587, acc=0.9018\n",
      "Epoch 03: train loss=0.3274, acc=0.9076 | val loss=0.3491, acc=0.9032\n",
      "Epoch 04: train loss=0.3070, acc=0.9129 | val loss=0.3480, acc=0.9041\n",
      "Epoch 05: train loss=0.2903, acc=0.9175 | val loss=0.3542, acc=0.9022\n",
      "Epoch 06: train loss=0.2772, acc=0.9209 | val loss=0.3577, acc=0.9026\n",
      "Epoch 07: train loss=0.2653, acc=0.9240 | val loss=0.3624, acc=0.9026\n",
      "Epoch 08: train loss=0.2553, acc=0.9268 | val loss=0.3663, acc=0.9035\n",
      "Epoch 09: train loss=0.2468, acc=0.9287 | val loss=0.3694, acc=0.9022\n",
      "Epoch 10: train loss=0.2385, acc=0.9307 | val loss=0.3780, acc=0.9011\n",
      "Epoch 11: train loss=0.2314, acc=0.9326 | val loss=0.3905, acc=0.9008\n",
      "Epoch 12: train loss=0.2255, acc=0.9340 | val loss=0.3987, acc=0.9001\n",
      "Epoch 13: train loss=0.2194, acc=0.9359 | val loss=0.4106, acc=0.8997\n",
      "Epoch 14: train loss=0.2141, acc=0.9372 | val loss=0.4140, acc=0.8979\n",
      "Epoch 15: train loss=0.2103, acc=0.9384 | val loss=0.4258, acc=0.8987\n",
      "Epoch 16: train loss=0.2057, acc=0.9393 | val loss=0.4290, acc=0.8994\n",
      "Epoch 17: train loss=0.2016, acc=0.9404 | val loss=0.4414, acc=0.8977\n",
      "Epoch 18: train loss=0.1979, acc=0.9414 | val loss=0.4552, acc=0.8959\n",
      "Epoch 19: train loss=0.1944, acc=0.9422 | val loss=0.4514, acc=0.8958\n",
      "Epoch 20: train loss=0.1917, acc=0.9430 | val loss=0.4607, acc=0.8956\n",
      "Epoch 21: train loss=0.1887, acc=0.9436 | val loss=0.4697, acc=0.8954\n",
      "Epoch 22: train loss=0.1856, acc=0.9446 | val loss=0.4828, acc=0.8922\n",
      "Epoch 23: train loss=0.1832, acc=0.9452 | val loss=0.4847, acc=0.8937\n",
      "Epoch 24: train loss=0.1808, acc=0.9461 | val loss=0.5054, acc=0.8926\n",
      "Epoch 25: train loss=0.1784, acc=0.9465 | val loss=0.5036, acc=0.8947\n",
      "Epoch 26: train loss=0.1765, acc=0.9471 | val loss=0.5091, acc=0.8916\n",
      "Epoch 27: train loss=0.1741, acc=0.9475 | val loss=0.5177, acc=0.8917\n",
      "Epoch 28: train loss=0.1726, acc=0.9478 | val loss=0.5337, acc=0.8918\n",
      "Epoch 29: train loss=0.1697, acc=0.9487 | val loss=0.5356, acc=0.8921\n",
      "Epoch 30: train loss=0.1689, acc=0.9486 | val loss=0.5397, acc=0.8904\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}: \"\n",
    "          f\"train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
    "          f\"val loss={val_loss:.4f}, acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b87366",
   "metadata": {},
   "source": [
    "10) Оценка качества на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75090b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: loss=0.2596, acc=0.9369\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"TEST: loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ceb2ad",
   "metadata": {},
   "source": [
    "В ходе обучения модели наблюдается рост точности на обучающей выборке от 0.878 до 0.949, что свидетельствует об успешной оптимизации. Однако уже после 4-5 эпох начинает проявляться переобучение, значение функции потерь на валидации увеличивается с 0.348 до 0.540, а точность на валидационной выборке снижается с 0.904 до 0.890. Следовательно, оптимальное число эпох для данной архитектуры составляет около 3-6, а дальнейшее обучение не улучшает качество обобщения. Точность на тестовой выборке после 30 эпох составила 0.937, что ниже возможного максимума из-за эффекта переобучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
